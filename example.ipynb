{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "**Sentiment Analysis of Movie Reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement:**\n",
    "\n",
    "In this, we have to predict the number of positive and negative reviews based on sentiments by using different classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1424638f5259100af9f9a5c1b05bd23cf5b71e51"
   },
   "source": [
    "**Import necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU cores.\n"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re, string, unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from tqdm import tqdm \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import os\n",
    "import warnings\n",
    "import multiprocessing\n",
    "\n",
    "cpus = multiprocessing.cpu_count()\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "pool = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(f'Using {multiprocessing.cpu_count()} CPU cores.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be1b642cce343f7a8f68f8c91f7c50372cdf4381"
   },
   "source": [
    "**Import the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4c593c17588723c0b0b0f19851cb70a8447ced76",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29341, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41411</td>\n",
       "      <td>I watched this film because I'm a big fan of R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37586</td>\n",
       "      <td>It does not seem that this movie managed to pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6017</td>\n",
       "      <td>Enough is not a bad movie , just mediocre .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44656</td>\n",
       "      <td>my friend and i rented this one a few nights a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38711</td>\n",
       "      <td>Just about everything in this movie is wrong, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24198</td>\n",
       "      <td>this isn't 'Bonnie and Clyde' or 'Thelma and L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37654</td>\n",
       "      <td>I have to say that I really liked UNDER SIEGE ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45340</td>\n",
       "      <td>Kramer Vs. Kramer is a near-heartening drama a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9745</td>\n",
       "      <td>Like the other comments says, this might be su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55813</td>\n",
       "      <td>The tunes are the best aspect of this televisi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             review  sentiment\n",
       "0  41411  I watched this film because I'm a big fan of R...          0\n",
       "1  37586  It does not seem that this movie managed to pl...          1\n",
       "2   6017        Enough is not a bad movie , just mediocre .          0\n",
       "3  44656  my friend and i rented this one a few nights a...          0\n",
       "4  38711  Just about everything in this movie is wrong, ...          0\n",
       "5  24198  this isn't 'Bonnie and Clyde' or 'Thelma and L...          1\n",
       "6  37654  I have to say that I really liked UNDER SIEGE ...          0\n",
       "7  45340  Kramer Vs. Kramer is a near-heartening drama a...          1\n",
       "8   9745  Like the other comments says, this might be su...          0\n",
       "9  55813  The tunes are the best aspect of this televisi...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the training data\n",
    "# imdb_data=pd.read_csv('data/train.csv')\n",
    "imdb_data=pd.read_csv('data/processed_train.csv')\n",
    "print(imdb_data.shape)\n",
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29341, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22622</td>\n",
       "      <td>Robert Lansing plays a scientist experimenting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10162</td>\n",
       "      <td>Well I've enjoy this movie, even though someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17468</td>\n",
       "      <td>First things first - though I believe Joel Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42579</td>\n",
       "      <td>I watched this movie on the grounds that Amber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>A certain sexiness underlines even the dullest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13418</td>\n",
       "      <td>Why did they change the cute, Rugrats televisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50674</td>\n",
       "      <td>Who will love my children has changed my heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33704</td>\n",
       "      <td>Im gonna make this short and sweet because i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21242</td>\n",
       "      <td>Though I never like to be the sort of person w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40345</td>\n",
       "      <td>The main aspect about the Superstar's movies a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                             review\n",
       "0  22622  Robert Lansing plays a scientist experimenting...\n",
       "1  10162  Well I've enjoy this movie, even though someti...\n",
       "2  17468  First things first - though I believe Joel Sch...\n",
       "3  42579  I watched this movie on the grounds that Amber...\n",
       "4    701  A certain sexiness underlines even the dullest...\n",
       "5  13418  Why did they change the cute, Rugrats televisi...\n",
       "6  50674  Who will love my children has changed my heart...\n",
       "7  33704  Im gonna make this short and sweet because i d...\n",
       "8  21242  Though I never like to be the sort of person w...\n",
       "9  40345  The main aspect about the Superstar's movies a..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the testing data\n",
    "# imdb_test_data=pd.read_csv('data/test.csv')\n",
    "imdb_test_data=pd.read_csv('data/processed_test.csv')\n",
    "print(imdb_test_data.shape)\n",
    "imdb_test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ad3773974351ed9bdf389b2847d7475b36c2295"
   },
   "source": [
    "**Exploratery data analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7f11c83b1320c8982b36889145f7f770563674a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29341.000000</td>\n",
       "      <td>29341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29348.411097</td>\n",
       "      <td>0.509662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17002.074346</td>\n",
       "      <td>0.499915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14564.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29348.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44162.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58681.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     sentiment\n",
       "count  29341.000000  29341.000000\n",
       "mean   29348.411097      0.509662\n",
       "std    17002.074346      0.499915\n",
       "min        4.000000      0.000000\n",
       "25%    14564.000000      0.000000\n",
       "50%    29348.000000      1.000000\n",
       "75%    44162.000000      1.000000\n",
       "max    58681.000000      1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "453c3fd238f62ab8f649eb01771817e25bc0c77d"
   },
   "source": [
    "**Sentiment count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "cb6bb97b0f851947dcf341a1de5708a1f2bc64c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14954\n",
       "0    14387\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f61964573faababe1f7897b77d32815a24954d2f"
   },
   "source": [
    "**Spliting the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d3aaabff555e07feb11c72cc3a6e457615975ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29341,) (29341,)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset  \n",
    "#train dataset\n",
    "train_reviews=imdb_data.review\n",
    "train_sentiments=imdb_data.sentiment\n",
    "#test dataset\n",
    "test_reviews=imdb_test_data.review\n",
    "# test_sentiments=imdb_test_data.sentiment\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "# print(test_reviews.shape,test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90da29c3b79f46f41d7391a2a116065b616d0fac"
   },
   "source": [
    "**Text normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "328b6e5977da3e055ad4b2e11a31e5e12ccf3b16"
   },
   "source": [
    "**Removing html strips and noise text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_processing_pipeline():\n",
    "\n",
    "    try:\n",
    "        nlp = spacy.load('en_core_web_lg') # spacy model\n",
    "    except:\n",
    "        raise ValueError('spaCy en_core_web_lg model not found.')\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        # self.text = \" \".join([w.lemma_ for w in self.nlp(text)])\n",
    "        self.nlp = nlp \n",
    "        self.tokens = None\n",
    "        self.rm_tokens = None\n",
    "        self.rm_text = None\n",
    "\n",
    "     # Removing the html strips\n",
    "    def strip_html(self):\n",
    "        soup = BeautifulSoup(self.text, \"html.parser\")\n",
    "        self.text = soup.get_text().lower()\n",
    "        return self\n",
    "\n",
    "    def text_preprocessor(self, remove_stopwords=True):\n",
    "        \"\"\"\n",
    "        - Lowercase the sentence\n",
    "        - Change \"'t\" to \"not\"\n",
    "        - Remove \"@name\"\n",
    "        - Isolate and remove punctuations except \"?\"\n",
    "        - Remove other special characters\n",
    "        - Remove stop words\n",
    "        - Remove trailing whitespace\n",
    "        \"\"\"\n",
    "\n",
    "        s = self.text\n",
    "\n",
    "        # Change 't to 'not'\n",
    "        s = re.sub(r\"\\'t\", \" not\", s)\n",
    "        # Remove @name\n",
    "        s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "        # Isolate and remove punctuations except '?'\n",
    "        s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "        s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "        # Removing the square brackets\n",
    "        s = re.sub('\\[[^]]*\\]', '', s)\n",
    "        # Remove some special characters\n",
    "        s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "        s = re.sub(r'[^a-zA-z0-9\\s]','',s)\n",
    "        # Remove trailing whitespace\n",
    "        s = re.sub(r'\\s+', ' ', s).strip()\n",
    "\n",
    "        self.tokens = [str(t) for t in self.nlp(s)]\n",
    "\n",
    "        if remove_stopwords:\n",
    "            self.rm_tokens = [w for w in self.tokens if w not in STOP_WORDS]\n",
    "            self.rm_text = \" \".join([t for t in self.rm_tokens])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Stemming the text\n",
    "    def simple_stemmer(self):\n",
    "        ps = nltk.porter.PorterStemmer()\n",
    "        self.text= ' '.join([ps.stem(word) for word in self.text.split()])\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def lemmatize(text, nlp):\n",
    "        return (\" \".join([w.lemma_ for w in nlp(text)]))\n",
    "\n",
    "    def main_pipeline(self):\n",
    "        return self.lemmatize(self.strip_html().text_preprocessor().get_rm_text(), nlp)\n",
    "\n",
    "    def get_text(self):\n",
    "        return self.text\n",
    "\n",
    "    def get_tokens(self):\n",
    "        return self.tokens\n",
    "\n",
    "    def get_rm_text(self):\n",
    "        return self.rm_text\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"text_processing_pipeline([text = '{self.text}'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kramer Vs. Kramer is a near-heartening drama about shocking, drastic augmentations of the two subjects of a failed married couple. Meryl Streep, in the throes of her trademark maternal sensitivity, plays an unhappy stay-at-home mother who feels confined to such a role and within the first five minutes of the film leaves her inattentive husband, in a fantastic performance by Dustin Hoffman, to find another role for herself. Hoffman is dumbstruck, having absolutely no idea what to do with himself, having taken so much for granted that he doesn't know the first thing about getting his son to school in the morning.<br /><br />Hoffman seamlessly characterizes this husband as such a juicy load of setbacks. He is restless, relentless and impatient, but even though the positive side to those three adjectives should include just the opposite, he is unremittingly fixated on whatever he turns his head to. He's been focused on his career in advertising, and when he is left to raise his son Billy all by himself, chaos ushers in immediately. He's the one throwing temper tantrums and quitting angrily halfway through an activity. After awhile, as he befriends his neighbor and Joanna's former friend, played by sexy Jane Alexander, Hoffman cools his jets enough to understand why his wife left. In the meantime, his boundless energy redirects towards raising Billy and he loses his job.<br /><br />The custody battle of the title is a brilliantly grey circumstance. Even if the ending is a little unmotivated, subjectified for the audience, the last line and the last shot still have that witty screen writing touch that seemed to diminish after the magical 1970s.\n"
     ]
    }
   ],
   "source": [
    "print(imdb_data.loc[7,'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kramer vs kramer near hearten drama shock drastic augmentation subject fail marry couple meryl streep throe trademark maternal sensitivity play unhappy stay home mother feels confine role minute film leave inattentive husband fantastic performance dustin hoffman find role hoffman dumbstruck have absolutely idea having taken grant doesn know thing get son school morning hoffman seamlessly characterize husband juicy load setback restless relentless impatient positive adjective include opposite unremittingly fixated turn head s focused career advertising left raise son billy chaos usher immediately s throw temper tantrum quit angrily halfway activity awhile befriend neighbor joanna s friend play sexy jane alexander hoffman cool jet understand wife leave meantime boundless energy redirect raise billy lose job custody battle title brilliantly grey circumstance end little unmotivated subjectified audience line shoot witty screen write touch diminish magical 1970'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Usage Example\"\"\"\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# text_processing_pipeline.lemmatize(text_processing_pipeline(imdb_data.loc[7,'review']).strip_html().text_preprocessor().get_rm_text(), nlp)\n",
    "text_processing_pipeline(imdb_data.loc[7,'review']).main_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29341/29341 [23:56<00:00, 20.42it/s]CPU times: user 23min 44s, sys: 3.36 s, total: 23min 47s\n",
      "Wall time: 23min 56s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_text = []\n",
    "\n",
    "for text in tqdm(imdb_data['review']):\n",
    "    tmp = text_processing_pipeline(text).main_pipeline()\n",
    "    processed_text.append(tmp)\n",
    "\n",
    "imdb_data['processed_review'] = processed_text\n",
    "\n",
    "# def mp_wrapper(text):\n",
    "#     return text_processing_pipeline(text).main_pipeline()\n",
    "\n",
    "# processed_text = list(map(mp_wrapper, imdb_data['review']))\n",
    "# mp_wrapper(imdb_data.loc[7,'review'])\n",
    "# processed_text = list(tqdm(pool.imap(mp_wrapper, imdb_data['review']), total=len(imdb_data['review'])))\n",
    "\n",
    "# processed_text = list(tqdm(pool.imap(mp_wrapper, list(imdb_data.loc[0:3,'review'])), total=len(list(imdb_data.loc[0:3,'review']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41411</td>\n",
       "      <td>I watched this film because I'm a big fan of R...</td>\n",
       "      <td>0</td>\n",
       "      <td>watch film m big fan river phoenix joaquin pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37586</td>\n",
       "      <td>It does not seem that this movie managed to pl...</td>\n",
       "      <td>1</td>\n",
       "      <td>movie manage lot people see place bump acciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6017</td>\n",
       "      <td>Enough is not a bad movie , just mediocre .</td>\n",
       "      <td>0</td>\n",
       "      <td>bad movie mediocre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44656</td>\n",
       "      <td>my friend and i rented this one a few nights a...</td>\n",
       "      <td>0</td>\n",
       "      <td>friend rent night ago single good movie see me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38711</td>\n",
       "      <td>Just about everything in this movie is wrong, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>movie wrong wrong wrong mike myers example s r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>8019</td>\n",
       "      <td>It 's one of the most honest films ever made a...</td>\n",
       "      <td>1</td>\n",
       "      <td>s honest film hollywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>453</td>\n",
       "      <td>An absorbing and unsettling psychological drama .</td>\n",
       "      <td>1</td>\n",
       "      <td>absorb unsettling psychological drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>13097</td>\n",
       "      <td>Soylent Green IS...a really good movie, actual...</td>\n",
       "      <td>1</td>\n",
       "      <td>soylent green good movie actually ve think don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>26896</td>\n",
       "      <td>There just isn't enough here. There a few funn...</td>\n",
       "      <td>0</td>\n",
       "      <td>isn funny spot disappoint love stupid movie ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29340</th>\n",
       "      <td>27094</td>\n",
       "      <td>This show was absolutely terrible. For one Geo...</td>\n",
       "      <td>0</td>\n",
       "      <td>absolutely terrible george isn funny kid snobb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29341 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             review  sentiment  \\\n",
       "0      41411  I watched this film because I'm a big fan of R...          0   \n",
       "1      37586  It does not seem that this movie managed to pl...          1   \n",
       "2       6017        Enough is not a bad movie , just mediocre .          0   \n",
       "3      44656  my friend and i rented this one a few nights a...          0   \n",
       "4      38711  Just about everything in this movie is wrong, ...          0   \n",
       "...      ...                                                ...        ...   \n",
       "29336   8019  It 's one of the most honest films ever made a...          1   \n",
       "29337    453  An absorbing and unsettling psychological drama .          1   \n",
       "29338  13097  Soylent Green IS...a really good movie, actual...          1   \n",
       "29339  26896  There just isn't enough here. There a few funn...          0   \n",
       "29340  27094  This show was absolutely terrible. For one Geo...          0   \n",
       "\n",
       "                                        processed_review  \n",
       "0      watch film m big fan river phoenix joaquin pho...  \n",
       "1      movie manage lot people see place bump acciden...  \n",
       "2                                     bad movie mediocre  \n",
       "3      friend rent night ago single good movie see me...  \n",
       "4      movie wrong wrong wrong mike myers example s r...  \n",
       "...                                                  ...  \n",
       "29336                            s honest film hollywood  \n",
       "29337              absorb unsettling psychological drama  \n",
       "29338  soylent green good movie actually ve think don...  \n",
       "29339  isn funny spot disappoint love stupid movie ex...  \n",
       "29340  absolutely terrible george isn funny kid snobb...  \n",
       "\n",
       "[29341 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imdb_data.to_csv('./data/processed_train.csv',index=0)\n",
    "imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29341/29341 [19:50<00:00, 24.65it/s]CPU times: user 19min 50s, sys: 2.13 s, total: 19min 52s\n",
      "Wall time: 19min 50s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_text = []\n",
    "\n",
    "for text in tqdm(imdb_test_data['review']):\n",
    "    tmp = text_processing_pipeline(text).main_pipeline()\n",
    "    processed_text.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22622</td>\n",
       "      <td>Robert Lansing plays a scientist experimenting...</td>\n",
       "      <td>robert lansing play scientist experiment pass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10162</td>\n",
       "      <td>Well I've enjoy this movie, even though someti...</td>\n",
       "      <td>ve enjoy movie turn stereotypical situation nt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17468</td>\n",
       "      <td>First things first - though I believe Joel Sch...</td>\n",
       "      <td>thing believe joel schumacher well mediocre di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42579</td>\n",
       "      <td>I watched this movie on the grounds that Amber...</td>\n",
       "      <td>watch movie ground amber benson rock nick stah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>A certain sexiness underlines even the dullest...</td>\n",
       "      <td>certain sexiness underline dull tangent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>30370</td>\n",
       "      <td>It is difficult to rate a writer/director's fi...</td>\n",
       "      <td>difficult rate writer director s effort movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>18654</td>\n",
       "      <td>After watching this movie once, it quickly bec...</td>\n",
       "      <td>watch movie quickly favorite different event h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>47985</td>\n",
       "      <td>Even though i sat and watched the whole thing,...</td>\n",
       "      <td>sit watch thing good place big chunk informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>9866</td>\n",
       "      <td>Warning Spoilers following. Superb recreation ...</td>\n",
       "      <td>warn spoiler follow superb recreation base ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29340</th>\n",
       "      <td>35559</td>\n",
       "      <td>My, my, my: Peter Cushing and Donald Pleasance...</td>\n",
       "      <td>peter cushing donald pleasance desperate work ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29341 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             review  \\\n",
       "0      22622  Robert Lansing plays a scientist experimenting...   \n",
       "1      10162  Well I've enjoy this movie, even though someti...   \n",
       "2      17468  First things first - though I believe Joel Sch...   \n",
       "3      42579  I watched this movie on the grounds that Amber...   \n",
       "4        701  A certain sexiness underlines even the dullest...   \n",
       "...      ...                                                ...   \n",
       "29336  30370  It is difficult to rate a writer/director's fi...   \n",
       "29337  18654  After watching this movie once, it quickly bec...   \n",
       "29338  47985  Even though i sat and watched the whole thing,...   \n",
       "29339   9866  Warning Spoilers following. Superb recreation ...   \n",
       "29340  35559  My, my, my: Peter Cushing and Donald Pleasance...   \n",
       "\n",
       "                                        processed_review  \n",
       "0      robert lansing play scientist experiment pass ...  \n",
       "1      ve enjoy movie turn stereotypical situation nt...  \n",
       "2      thing believe joel schumacher well mediocre di...  \n",
       "3      watch movie ground amber benson rock nick stah...  \n",
       "4                certain sexiness underline dull tangent  \n",
       "...                                                  ...  \n",
       "29336  difficult rate writer director s effort movie ...  \n",
       "29337  watch movie quickly favorite different event h...  \n",
       "29338  sit watch thing good place big chunk informati...  \n",
       "29339  warn spoiler follow superb recreation base ant...  \n",
       "29340  peter cushing donald pleasance desperate work ...  \n",
       "\n",
       "[29341 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imdb_test_data.to_csv('./data/processed_test.csv',index=0)\n",
    "imdb_test_data['processed_review'] = processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29341,)\n",
      "(29341,)\n"
     ]
    }
   ],
   "source": [
    "norm_train_reviews = imdb_data.review\n",
    "norm_test_reviews=imdb_test_data.review\n",
    "\n",
    "print(norm_train_reviews.shape)\n",
    "print(norm_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c2a872ffcb6b8076fdbbba641af12081b6022ef"
   },
   "source": [
    "**Bags of words model **\n",
    "\n",
    "It is used to convert text documents to numerical vectors or bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "35cf9dcefb40b2dc520c5b0d559695324c46cc04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (29341, 4272351)\n",
      "BOW_cv_test: (29341, 4272351)\n"
     ]
    }
   ],
   "source": [
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "cv_test_reviews=cv.transform(norm_test_reviews)\n",
    "\n",
    "print('BOW_cv_train:',cv_train_reviews.shape)\n",
    "print('BOW_cv_test:',cv_test_reviews.shape)\n",
    "#vocab=cv.get_feature_names()-toget feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52371868f05ff9cf157280c5acf0f5bc71ee176d"
   },
   "source": [
    "**Term Frequency-Inverse Document Frequency model (TFIDF)**\n",
    "\n",
    "It is used to convert text documents to  matrix of  tfidf features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "afe6de957339921e05a6faeaf731f2272fd31946",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (29341, 4272351)\n",
      "Tfidf_test: (29341, 4272351)\n"
     ]
    }
   ],
   "source": [
    "#Tfidf vectorizer\n",
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(norm_test_reviews)\n",
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "803e92b25faa738b10928a91de72d177d8dddf85"
   },
   "source": [
    "**Labeling the sentiment text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60f5d496ce4109d1cdbf08f4284d4d26efd93922"
   },
   "outputs": [],
   "source": [
    "#labeling the sentient data\n",
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(imdb_data['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21a80c94fb42e14391c627710c5d796c40aa7dde"
   },
   "source": [
    "**Split the sentiment tdata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "ca1e4cc917265ac98a72c37cffe57f27e9897408"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentiment'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d39787debddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Spliting the sentiment data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_sentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_sentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2891\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentiment'"
     ]
    }
   ],
   "source": [
    "#Spliting the sentiment data\n",
    "train_sentiments = imdb_data['sentiment']\n",
    "test_sentiments = imdb_test_data['sentiment']\n",
    "print(train_sentiments)\n",
    "print(test_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelling the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d5e45fdc9d062a5b9b9dd665ffe732776e196953"
   },
   "source": [
    "Let us build logistic regression model for both bag of words and tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "142d007421900550079a12ae8655bcae678ebaad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n",
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
    "print(lr_bow)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07eb6d52eb32469e3be82e90af636d598a7b7c27"
   },
   "source": [
    "**Logistic regression model performane on test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "52ad86935b76117f97b79e6672a3ba12352b9461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 0]\n",
      "[1 1 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict=lr.predict(cv_test_reviews)\n",
    "print(lr_bow_predict)\n",
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=lr.predict(tv_test_reviews)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_sentiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-539eb544b8eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Accuracy score for bag of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr_bow_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_bow_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr_bow_score :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_bow_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Accuracy score for tfidf features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr_tfidf_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentiments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_tfidf_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_sentiments' is not defined"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "lr_bow_score=accuracy_score(test_sentiments,lr_bow_predict)\n",
    "print(\"lr_bow_score :\",lr_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac2ec8353acb5e0f548e1e4a590fbe6f34f4a686"
   },
   "source": [
    "**Print the classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f89c7e7a6136d08790ffbf6bc4d0d05455f8555a"
   },
   "outputs": [],
   "source": [
    "#Classification report for bag of words \n",
    "lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n",
    "print(lr_bow_report)\n",
    "\n",
    "#Classification report for tfidf features\n",
    "lr_tfidf_report=classification_report(test_sentiments,lr_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d2e5ddcd69ff0fb52f05f17fc74a86e1b5e5b61"
   },
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a36c058e834938559b7202f2142e61423a613b7a"
   },
   "outputs": [],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,lr_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fde9753386e3593dc27c4e88e02bdc38462a018"
   },
   "source": [
    "**Stochastic gradient descent or Linear support vector machines for bag of words and tfidf features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2211a9e97682195a0372b33e4da7267aad8548db"
   },
   "outputs": [],
   "source": [
    "#training the linear svm\n",
    "svm=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
    "#fitting the svm for bag of words\n",
    "svm_bow=svm.fit(cv_train_reviews,train_sentiments)\n",
    "print(svm_bow)\n",
    "#fitting the svm for tfidf features\n",
    "svm_tfidf=svm.fit(tv_train_reviews,train_sentiments)\n",
    "print(svm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9a7a973591c1d3cabaa1a47c57fa029d3752bab"
   },
   "source": [
    "**Model performance on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a5ab738e04f0f9082c8d6ade6c2148cc398f8f3"
   },
   "outputs": [],
   "source": [
    "#Predicting the model for bag of words\n",
    "svm_bow_predict=svm.predict(cv_test_reviews)\n",
    "print(svm_bow_predict)\n",
    "#Predicting the model for tfidf features\n",
    "svm_tfidf_predict=svm.predict(tv_test_reviews)\n",
    "print(svm_tfidf_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score for bag of words\n",
    "svm_bow_score=accuracy_score(test_sentiments,svm_bow_predict)\n",
    "print(\"svm_bow_score :\",svm_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "svm_tfidf_score=accuracy_score(test_sentiments,svm_tfidf_predict)\n",
    "print(\"svm_tfidf_score :\",svm_tfidf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1bd245f50902ad87ca28e48cbce64ec6a16ec5a"
   },
   "source": [
    "**Print the classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d112bc5b4944330b567e19a7e04544a9a459f238"
   },
   "outputs": [],
   "source": [
    "#Classification report for bag of words \n",
    "svm_bow_report=classification_report(test_sentiments,svm_bow_predict,target_names=['Positive','Negative'])\n",
    "print(svm_bow_report)\n",
    "#Classification report for tfidf features\n",
    "svm_tfidf_report=classification_report(test_sentiments,svm_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(svm_tfidf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "705fd8ae8bb5e6925852fffc906b6ffd769dbac0"
   },
   "source": [
    "**Plot the confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49cde912705acbaef90d7a269cd27ea8a2815f03"
   },
   "outputs": [],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,svm_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,svm_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial Naive Bayes for bag of words and tfidf features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "mnb=MultinomialNB()\n",
    "#fitting the svm for bag of words\n",
    "mnb_bow=mnb.fit(cv_train_reviews,train_sentiments)\n",
    "print(mnb_bow)\n",
    "#fitting the svm for tfidf features\n",
    "mnb_tfidf=mnb.fit(tv_train_reviews,train_sentiments)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model performance on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model for bag of words\n",
    "mnb_bow_predict=mnb.predict(cv_test_reviews)\n",
    "print(mnb_bow_predict)\n",
    "#Predicting the model for tfidf features\n",
    "mnb_tfidf_predict=mnb.predict(tv_test_reviews)\n",
    "print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score for bag of words\n",
    "mnb_bow_score=accuracy_score(test_sentiments,mnb_bow_predict)\n",
    "print(\"mnb_bow_score :\",mnb_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n",
    "print(\"mnb_tfidf_score :\",mnb_tfidf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report for bag of words \n",
    "mnb_bow_report=classification_report(test_sentiments,mnb_bow_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_bow_report)\n",
    "#Classification report for tfidf features\n",
    "mnb_tfidf_report=classification_report(test_sentiments,mnb_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,mnb_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,mnb_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "* We can observed that both logistic regression and multinomial naive bayes model performing well compared to linear support vector  machines.\n",
    "* Still we can improve the accuracy of the models by preprocessing data and by using lexicon models like Textblob."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
